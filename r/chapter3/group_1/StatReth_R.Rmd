---
title: "Statistical Rethingking with R"
author: "Dilsad"
date: "5/5/2021"
output: html_document
---

This file is for working on the Statistical Rethinking book.  
by Richard McElreath  
2nd Edition, 2020  

Date: 05/2021  
Author: Dilsad Dagtekin  

### House keeping and loading libraries and data

```{r setup, include=TRUE, message=FALSE}
# for "rethinking" package
# library(devtools)
# evtools::install_github('rmcelreath/rethinking', force=T)

load.libraries <- function(){
  library(coda)
  library(mvtnorm)
  library(dagitty)
  library(ellipse)
  library(ape)
  library(rstan)
  library(rethinking)
  
}

load.libraries()
```

### Code in the book  
  
  
### Chapter 2  
  
  
```{r}
ways <- c( 0 , 3 , 8 , 9 , 0 )
ways/sum(ways)  
```
  
  
##### 2.2  
  
  
```{r}
dbinom( 6 , size=9 , prob=0.5 )
```

    
##### 2.3  
  
  
```{r}
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )
p_grid

# define prior
prior <- rep( 1 , 20 )
prior

# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
likelihood

# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
unstd.posterior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
posterior

```

    
##### 2.4  
  
  
```{r}
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
```

    
##### 2.5  
  
  
```{r}
prior <- ifelse( p_grid < 0.5 , 0 , 1 )
prior

# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )

# compute product of likelihood and prior
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)

plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
```
  
  

```{r}
prior <- exp( -5*abs( p_grid - 0.5 ) )
prior

# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)

plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
```
   
    
##### 2.6  
  
  
```{r}
# library(rethinking)
# quap function is a flexible model fitting tool that will 
# allow us to specify a large number of different “regression” models.

globe.qa <- quap(
  alist(W ~ dbinom( W+L ,p), # binomial likelihood
        p ~ dunif(0,1)), # uniform prior
  data=list(W=6,L=3)) # display summary of quadratic approximation
globe.qa
precis(globe.qa)
```

    
##### 2.7  
  
  
```{r}
# analytical calculation
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE , col="red")
```

    
##### 2.8  
  
  
```{r}
# MCMC algorithm example for globe tossing example
# with Metropolis algorithm (more in Chapter  9)
n_samples <- 1000
p <- rep(NA , n_samples)
p[1] <- 0.5
W <- 6
L <- 3
for (i in 2:n_samples) {
  p_new <- rnorm(1 , p[i-1] , 0.1)
  if (p_new < 0) p_new <- abs(p_new)
  if (p_new > 1) p_new <- 2 - p_new
  q0 <- dbinom(W , W+L , p[i-1])
  q1 <- dbinom(W , W+L , p_new)
  p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )
}

str(p)
```

    
##### 2.9  
  
  
```{r}
dens( p , xlim=c(0,1) )
curve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE, col="red" )
```

### Chapter 3  
  
  
##### 3.1  
  
  
```{r}
# What do we know?
# Pr(positive|vampire) = 0.95
# Pr(positive|mortal) = 0.01
# Pr(vampire) = 0.001 --> prior
# Calculate: Pr(vampire|positive)

# Solution:
# Pr(vampire|positive) = (Pr(positive|vampire)*Pr(vampire))/ Pr(positive)

Pr_Positive_Vampire <- 0.95 
Pr_Positive_Mortal <- 0.01 
Pr_Vampire <- 0.001 

# Pr(positive) =  your test is positive and you are a vampire + your test is positive but you are a mortal
Pr_Positive <- Pr_Positive_Vampire * Pr_Vampire + 
  Pr_Positive_Mortal * (1 - Pr_Vampire)

(Pr_Vampire_Positive <- Pr_Positive_Vampire*Pr_Vampire / Pr_Positive)

```
  
  
##### 3.2  
  
  
```{r}
# Before beginning to work with samples, we need to generate them. 
# Here’s a reminder for how to compute the posterior for the 
# globe tossing model, using grid approximation. 
# Remember, the posterior here means the probability of p conditional on the data.

p_grid <- seq(from=0 , to=1 , length.out=1000)
prob_p <- rep(1 , 1000)
prob_data <- dbinom(6 , size=9 , prob=p_grid)
posterior <- prob_data * prob_p 
posterior <- posterior / sum(posterior)
str(posterior)
```
  
  
##### 3.3  
  
  
```{r}
# Now we wish to draw 10,000 samples from this posterior. 

samples <- sample(p_grid , prob=posterior , size=1e4 , replace=TRUE)
str(samples)
```
  
  
##### 3.4  
  
  
```{r}

plot(samples)

```
  
  
##### 3.5  
  
  
```{r}
# library(rethinking)
# The density ofsamples (vertical) at each parameter value (horizontal).
dens(samples)

```
  
  
Once your model produces a posterior distribution, the model’s work is done.  
But your work has just begun. It is necessary to summarize and interpret the posterior distribution.  
Exactly how it is summarized depends upon your purpose.  
But common questions include:  
- How much posterior probability lies below some parameter value?  
- How much posterior probability lies between two parameter values?  
- Which parameter value marks the lower 5% of the posterior probability?  
- Which range of parameter values contains 90% of the posterior probability?  
- Which parameter value has highest posterior probability?  
  
These simple questions can be usefully divided into questions about  
(1) intervals of defined boundaries  
(2) questions about intervals of defined probability mass  
(3) questions about point estimates.  
  

##### 3.2.1 Intervals of defined boundaries  
  

##### 3.6  
  
  
```{r}
# add up posterior probability where p < 0.5

sum(posterior[ p_grid < 0.5 ])

```
  

##### 3.7  
  
  
```{r}
# So let’s see how to perform the same calculation, using samples from the posterior.
# add up all of the samples below 0.5, but also divide the resulting count by the total number of samples.
# In other words, find the frequency of parameter values below 0.5:

sum(samples < 0.5)/1e4

```
  

##### 3.8  
  
  
```{r}
# Using the same approach, you can ask how much posterior probability lies between 0.5 and 0.75:

sum(samples > 0.5 & samples < 0.75) / 1e4

```
  

##### 3.2.2 Intervals of defined mass  
  
a.k.a confidence interval, credible interval, compatibility interval
  

##### 3.9  
  
  
```{r}
# boundaries of the lower 80% posterior probability.

quantile(samples, 0.8)

```
    

##### 3.10  
  
  
```{r}
# the middle 80% interval lies between the 10th percentile and the 90th percentile.
# Intervals of this sort, which assign equal probability mass to each tail, 
# are very common in the scientific literature.
#We’ll call them percentile intervals (PI).

quantile(samples, c(0.1, 0.9))

```
    

##### 3.11  
  
  
```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prior <- rep(1,1000) 
likelihood <- dbinom( 3 , size=3 , prob=p_grid ) 
posterior <- likelihood * prior 
posterior <- posterior / sum(posterior) 
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )

str(samples)

```
    

##### 3.12  
  
  
```{r}
# library(rethinking)
# PI function calculates "percentile intervals"
PI( samples , prob=0.5 )

```
    

##### 3.13  
  
  
```{r}
# the 50% highest posterior density interval (HPDI).
# The HPDI is the narrowest interval containing the specified probability mass.
# If you think about it, there must be an infinite number of posterior intervals with the same mass.
# But if you want an interval that best represents the parameter values most consistent with the data, 
# then you want the densest of these intervals.

# library(rethinking)
# HPDI function calculates "highest posterior density interval"
HPDI( samples , prob=0.5 )

```
  

##### 3.2.3 Point estimates  
Given the entire posterior distribution, what value should you report?  
  
Consider the following example.  
Suppose again the globe tossing experiment in which we observe 3 waters out of 3 tosses.  
Let’s consider three alternative point estimates.  
  

##### 3.14  
  
  
```{r}
# First - report the parameter value with highest posterior probability, a maximum a posteriori (MAP) estimate.

p_grid[ which.max(posterior) ]

```
  

##### 3.15  
  
  
```{r}
# Or if you instead have samples from the posterior, you can still approximate the same point:

# library(rethinking)
# chainmode functions finds mode of a continous density estimate

chainmode( samples , adj=0.01 )

```
  

##### 3.16  
  
  
```{r}

mean(samples)
median(samples)

```
  

##### 3.17  
  
  
```{r}
# How to choose between mode, mean, and median?
# choose a loss function.
# the loss is proportional to the distance of your decision from the true value.

# It turns out that the parameter value that maximizes expected winnings
# (minimizes expected loss) is the median of the posterior distribution.

# Calculating expected loss for any given decision means 
# using the posterior to average over our uncertainty in the true value

# So suppose we decide p = 0.5 will be our decision. Then the expected loss will be
sum( posterior*abs( 0.5 - p_grid ) )
```

All the code above does is compute the weighted average loss, where each loss is weighted by its corresponding posterior probability.  
  
There’s a trick for repeating this calculation for every possible decision, using the function sapply.  
  

##### 3.18  
  
  
```{r}
loss <- sapply( p_grid , function(d) sum( posterior*abs( d - p_grid ) ) )
str(loss)
```
  
Now the symbol loss contains a list of loss values, one for each possible decision, corresponding the values in p_grid. From here, it’s easy to find the parameter value that minimizes the loss:  
  

##### 3.19  
  
  
```{r}
p_grid[ which.min(loss) ]
```

And this is actually the posterior median, the parameter value that splits the posterior density such that half of the mass is above it and half below it.  
Try median(samples) for comparison. It may not be exactly the same value, due to sampling variation, but it will be close.  
  
```{r}
median(samples)
```

##### Section 3.3
  
  
##### 3.20  
  
  
```{r}
dbinom( 0:2 , size=2 , prob=0.7 )
```
  
  
##### 3.21  
  
  
```{r}
rbinom(1, size=2, prob=0.7)
```
  
  
##### 3.22  
  
  
```{r}
rbinom(10, size=2, prob=0.7)
```
  
  
Let’s generate 100,000 dummy observations, just to verify that each value (0, 1, or 2) appears in proportion to its likelihood:  
  
  
##### 3.23  
  
  
```{r}
dummy_w <- rbinom(1e5, size=2, prob=0.7)
table(dummy_w)/1e5
```
  
  
Only two tosses of the globe isn’t much of a sample, though.  
So now let’s simulate the same sample size as before, 9 tosses.  
  
  
##### 3.24  
  
  
```{r}
dummy_w <- rbinom( 1e5 , size=9 , prob=0.7 ) 
# library(rethinking)
simplehist( dummy_w , xlab="dummy water count" )
```
  
  
##### 3.25  
  
  
```{r}
w <- rbinom(1e4, size=9, prob=0.6)
# library(rethinking)
simplehist(w)
```
  
  
##### 3.26  
  
  
```{r}
w <- rbinom(1e4, size=9, prob=samples)
# library(rethinking)
simplehist(w)
```

